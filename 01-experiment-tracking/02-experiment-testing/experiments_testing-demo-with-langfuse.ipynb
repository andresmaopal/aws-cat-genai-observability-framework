{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Experiments tracking - AWS Strands Agents with LiteLLM and LangFuse observability\n",
    "\n",
    "This notebook demonstrates the unified testing approach using LiteLLM endpoints with the `run_test()` and `run_evaluation()` methods with human-readable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "______________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"strands-agents\" \"strands-agents-tools\" \"langfuse==3.1.1\" \"litellm\" opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, base64\n",
    "import time, uuid, boto3\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from utils_litellm import UnifiedTester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LiteLLM Unified Tester initialized!\n",
      "‚úÖ Available Prompts: ['version1', 'version2']\n",
      "‚úÖ Number of Test queries: 4\n"
     ]
    }
   ],
   "source": [
    "# Initialize LiteLLM Unified Tester\n",
    "tester = UnifiedTester()\n",
    "\n",
    "# Load configuration\n",
    "with open('config_experiments.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "prompts = config['system_prompts']\n",
    "test_queries = config['test_queries']\n",
    "\n",
    "print(\"‚úÖ LiteLLM Unified Tester initialized!\")\n",
    "print(f\"‚úÖ Available Prompts: {list(prompts.keys())}\")\n",
    "print(f\"‚úÖ Number of Test queries: {len(test_queries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangFuse Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangFuse v3 Environment Configured:\n",
      "   Host: http://xxxxxxxxxxx\n",
      "   OTEL Endpoint: http://xxxxxxxxxx/api/public/otel/v1/traces\n",
      "   Authentication: Configured\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1. Set general environment variables first\n",
    "\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-xxxxxxxxxxx\" # Your Langfuse project secret key\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-xxxxxxxxxxxxx\" # Your Langfuse project public key\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com/\" # Langfuse domain\n",
    "\n",
    "\n",
    "def setup_langfuse_v3(langfuse_public_key, langfuse_secret_key, langfuse_api_url):\n",
    "    \"\"\"Set up LangFuse v3 with proper configuration\"\"\"\n",
    "    \n",
    "    \n",
    "    # 2. Set up OpenTelemetry endpoint with proper authentication\n",
    "    otel_endpoint = f\"{langfuse_api_url}/api/public/otel/v1/traces\"\n",
    "    auth_token = base64.b64encode(\n",
    "        f\"{langfuse_public_key}:{langfuse_secret_key}\".encode()\n",
    "    ).decode()\n",
    "    \n",
    "    os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = otel_endpoint\n",
    "    os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {auth_token}\"\n",
    "    \n",
    "    print(\"‚úÖ LangFuse v3 Environment Configured:\")\n",
    "    print(f\"   Host: {langfuse_api_url}\")\n",
    "    print(f\"   OTEL Endpoint: {otel_endpoint}\")\n",
    "    print(f\"   Authentication: Configured\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Set up LangFuse\n",
    "setup_langfuse_v3(os.environ[\"LANGFUSE_PUBLIC_KEY\"], os.environ[\"LANGFUSE_SECRET_KEY\"], os.environ[\"LANGFUSE_HOST\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Definition\n",
    "__________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands_tools import retrieve, current_time\n",
    "from strands import Agent, tool\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS Clients setup (Bedrock KnowledgeBase and DynamoDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamoDB table: restaurant-bookings\n",
      "Knowledge Base Id: 9M16EZBECX\n"
     ]
    }
   ],
   "source": [
    "kb_name = \"restaurant-assistant\"\n",
    "dynamodb = boto3.resource(\"dynamodb\")\n",
    "smm_client = boto3.client(\"ssm\")\n",
    "table_name = smm_client.get_parameter(\n",
    "    Name=f\"{kb_name}-table-name\", WithDecryption=False\n",
    ")\n",
    "table = dynamodb.Table(table_name[\"Parameter\"][\"Value\"])\n",
    "kb_id = smm_client.get_parameter(Name=f\"{kb_name}-kb-id\", WithDecryption=False)\n",
    "print(\"DynamoDB table:\", table_name[\"Parameter\"][\"Value\"])\n",
    "print(\"Knowledge Base Id:\", kb_id[\"Parameter\"][\"Value\"])\n",
    "\n",
    "import uuid\n",
    "session_id = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tool_get_booking_details.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tool_get_booking_details.py\n",
    "\n",
    "from strands import tool\n",
    "import boto3 \n",
    "\n",
    "@tool\n",
    "def tool_booking_details(booking_id: str, restaurant_name: str) -> dict:\n",
    "    \"\"\"Get the relevant details for booking_id in restaurant_name\n",
    "    Args:\n",
    "        booking_id: the id of the reservation\n",
    "        restaurant_name: name of the restaurant handling the reservation\n",
    "\n",
    "    Returns:\n",
    "        booking_details: the details of the booking in JSON format\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = table.get_item(\n",
    "            Key={\"booking_id\": booking_id, \"restaurant_name\": restaurant_name}\n",
    "        )\n",
    "        if \"Item\" in response:\n",
    "            return response[\"Item\"]\n",
    "        else:\n",
    "            return f\"No booking found with ID {booking_id}\"\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tool_delete_booking.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tool_delete_booking.py\n",
    "\n",
    "from strands import tool\n",
    "import boto3 \n",
    "\n",
    "@tool\n",
    "def tool_delete_booking(booking_id: str, restaurant_name:str) -> str:\n",
    "    \"\"\"delete an existing booking_id at restaurant_name\n",
    "    Args:\n",
    "        booking_id: the id of the reservation\n",
    "        restaurant_name: name of the restaurant handling the reservation\n",
    "\n",
    "    Returns:\n",
    "        confirmation_message: confirmation message\n",
    "    \"\"\"\n",
    "    kb_name = 'restaurant-assistant'\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    smm_client = boto3.client('ssm')\n",
    "    table_name = smm_client.get_parameter(\n",
    "        Name=f'{kb_name}-table-name',\n",
    "        WithDecryption=False\n",
    "    )\n",
    "    table = dynamodb.Table(table_name[\"Parameter\"][\"Value\"])\n",
    "    try:\n",
    "        response = table.delete_item(Key={'booking_id': booking_id, 'restaurant_name': restaurant_name})\n",
    "        if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "            return f'Booking with ID {booking_id} deleted successfully'\n",
    "        else:\n",
    "            return f'Failed to delete booking with ID {booking_id}'\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tool_create_booking.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tool_create_booking.py\n",
    "\n",
    "#Alternativelly, you can use the TOOL_SPEC approach when defining your tool\n",
    "\n",
    "from typing import Any\n",
    "from strands.types.tools import ToolResult, ToolUse\n",
    "import boto3\n",
    "import uuid\n",
    "\n",
    "\n",
    "TOOL_SPEC = {\n",
    "    \"name\": \"tool_create_booking\",\n",
    "    \"description\": \"Create a new booking at restaurant_name\",\n",
    "    \"inputSchema\": {\n",
    "        \"json\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"date\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"\"\"The date of the booking in the format YYYY-MM-DD. \n",
    "                    Do NOT accept relative dates like today or tomorrow. \n",
    "                    Ask for today's date for relative date.\"\"\"\n",
    "                },\n",
    "                \"hour\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"the hour of the booking in the format HH:MM\"\n",
    "                },\n",
    "                \"restaurant_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"name of the restaurant handling the reservation\"\n",
    "                },\n",
    "                \"guest_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the customer to have in the reservation\"\n",
    "                },\n",
    "                \"num_guests\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of guests for the booking\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"date\", \"hour\", \"restaurant_name\", \"guest_name\", \"num_guests\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# Function name must match tool name\n",
    "def tool_create_booking(tool: ToolUse, **kwargs: Any) -> ToolResult:\n",
    "    kb_name = 'restaurant-assistant'\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    smm_client = boto3.client('ssm')\n",
    "    table_name = smm_client.get_parameter(\n",
    "        Name=f'{kb_name}-table-name',\n",
    "        WithDecryption=False\n",
    "    )\n",
    "    table = dynamodb.Table(table_name[\"Parameter\"][\"Value\"])\n",
    "    \n",
    "    tool_use_id = tool[\"toolUseId\"]\n",
    "    date = tool[\"input\"][\"date\"]\n",
    "    hour = tool[\"input\"][\"hour\"]\n",
    "    restaurant_name = tool[\"input\"][\"restaurant_name\"]\n",
    "    guest_name = tool[\"input\"][\"guest_name\"]\n",
    "    num_guests = tool[\"input\"][\"num_guests\"]\n",
    "    \n",
    "    results = f\"Creating reservation for {num_guests} people at {restaurant_name}, \" \\\n",
    "              f\"{date} at {hour} in the name of {guest_name}\"\n",
    "    print(results)\n",
    "    try:\n",
    "        booking_id = str(uuid.uuid4())[:8]\n",
    "        table.put_item(\n",
    "            Item={\n",
    "                'booking_id': booking_id,\n",
    "                'restaurant_name': restaurant_name,\n",
    "                'date': date,\n",
    "                'name': guest_name,\n",
    "                'hour': hour,\n",
    "                'num_guests': num_guests\n",
    "            }\n",
    "        )\n",
    "        return {\n",
    "            \"toolUseId\": tool_use_id,\n",
    "            \"status\": \"success\",\n",
    "            \"content\": [{\"text\": f\"Reservation created with booking id: {booking_id}\"}]\n",
    "        } \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"toolUseId\": tool_use_id,\n",
    "            \"status\": \"error\",\n",
    "            \"content\": [{\"text\": str(e)}]\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tool_create_booking\n",
    "import tool_delete_booking\n",
    "import tool_get_booking_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Tools List and KnowledgeBase Id capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Knowledge Base\n",
    "os.environ[\"KNOWLEDGE_BASE_ID\"] = kb_id[\"Parameter\"][\"Value\"]\n",
    "\n",
    "#Tools list\n",
    "tool_list = [retrieve, current_time, tool_get_booking_details, tool_create_booking, tool_delete_booking]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiteLLM Model Endpoints\n",
    "-----------------------------------------------------------------------------\n",
    "\n",
    "With LiteLLM, you can use various model endpoints. Here are some examples for AWS Bedrock:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests Setup\n",
    "_______________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting LiteLLM Test Suite\n",
      "üìä Total combinations to test: 2\n",
      "ü§ñ Models: ['bedrock/openai.gpt-oss-120b-1:0', 'bedrock/us.anthropic.claude-3-7-sonnet-20250219-v1:0']\n",
      "üìù Prompts: ['version2']\n",
      "‚ùì Queries: 1 query(ies)\n",
      "================================================================================\n",
      "\n",
      "[1/2] Testing: bedrock/openai.gpt-oss-120b-1:0 | version2\n",
      "Query: What is the current bitcoin price?\n",
      "------------------------------------------------------------\n",
      "üîß Using AWS region: us-east-1\n",
      "**Current Bitcoin (BTC) Price**\n",
      "\n",
      "- **Price:** **$‚ÄØ‚Äã27,842.31 USD**  \n",
      "- **Source:** Real‚Äëtime market data from major cryptocurrency exchanges (e.g., Coinbase, Binance, Kraken) aggregated via the Amazon Bedrock Knowledge Base.  \n",
      "- **Timestamp:** 2025‚Äë11‚Äë05‚ÄØ08:12‚ÄØUTC  \n",
      "\n",
      "*Disclaimer:* Cryptocurrency prices are highly volatile and can change within seconds. This figure reflects the price at the moment of retrieval and should not be considered financial advice. Always verify the latest price on a trusted exchange before making any trading decisions.\n",
      "Tool #1: retrieve\n",
      "I‚Äôm not able to pull live market data at the moment, so I can‚Äôt give you the exact current Bitcoin price.‚ÄØFor the most up‚Äëto‚Äëdate figure, please check a reliable financial source such as:\n",
      "\n",
      "- A major cryptocurrency exchange (e.g., Coinbase, Binance, Kraken)  \n",
      "- A financial news site (e.g., Bloomberg, Reuters, CNBC)  \n",
      "- A market‚Äëdata platform or app (e.g., Yahoo Finance, Google Finance, CoinMarketCap)\n",
      "\n",
      "These sources update Bitcoin‚Äôs price in real time and will give you the most accurate information.  \n",
      "\n",
      "*Disclaimer: Cryptocurrency prices can be highly volatile and may change rapidly. Always verify the latest price before making any investment decisions.*‚úÖ SUCCESS | Time: 4.51s\n",
      "\n",
      "[2/2] Testing: bedrock/us.anthropic.claude-3-7-sonnet-20250219-v1:0 | version2\n",
      "Query: What is the current bitcoin price?\n",
      "------------------------------------------------------------\n",
      "üîß Using AWS region: us-east-1\n",
      "I'd be happy to help you find the current Bitcoin price. However, I don't have direct access to real-time cryptocurrency market data through the available tools. \n",
      "\n",
      "To provide you with accurate and up-to-date information about Bitcoin's current price, I would need to:\n",
      "\n",
      "1. Access a financial data source or cryptocurrency exchange API\n",
      "2. Retrieve the latest Bitcoin price data\n",
      "3. Present it to you with the timestamp\n",
      "\n",
      "Unfortunately, the tools available to me don't include cryptocurrency market data retrieval. I can tell you the current time, but not the current Bitcoin price.\n",
      "\n",
      "Would you like me to:\n",
      "1. Provide general information about Bitcoin from our knowledge base?\n",
      "2. Suggest reliable sources where you can check the current Bitcoin price?‚úÖ SUCCESS | Time: 4.15s\n",
      "\n",
      "üéâ Test Suite Completed! 2 results generated.\n",
      "üìÅ Results automatically saved to test_results/test_results_20251105_161902.csv\n",
      "\n",
      "üìà RESULTS SUMMARY\n",
      "==================================================\n",
      "Total Tests: 2\n",
      "‚úÖ Successful: 2 (100.0%)\n",
      "‚ùå Failed: 0 (0.0%)\n",
      "‚è±Ô∏è  Response Times - Avg: 4.33s | Min: 4.15s | Max: 4.51s\n",
      "\n",
      "ü§ñ MODEL PERFORMANCE\n",
      "==================================================\n",
      "bedrock/openai.gpt-oss-120b-1:0          | Success: 100.0% | Avg Time:   4.51s | Tests: 1\n",
      "bedrock/us.anthropic.claude-3-7-sonnet-20250219-v1:0 | Success: 100.0% | Avg Time:   4.15s | Tests: 1\n",
      "\n",
      "üìù PROMPT PERFORMANCE\n",
      "==================================================\n",
      "version2             | Success: 100.0% | Avg Time:   4.33s | Tests: 2\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Multiple LiteLLM models, single system prompt, multiple queries\n",
    "\n",
    "#Test name\n",
    "test_name = \"Restaurant helper LiteLLM Test\"\n",
    "\n",
    "#Langfuse trace attributes\n",
    "trace_attributes = {\n",
    "    # Main trace name \n",
    "    \"operation.name\": test_name, \n",
    "    \"langfuse.trace.name\": test_name,\n",
    "    # Core identifiers\n",
    "    \"session.id\": session_id,\n",
    "    \"user.id\": \"palacan@amazon.com\",\n",
    "    # Langfuse metadata\n",
    "    \"langfuse.tags\": [\n",
    "        f\"Agent-{test_name}\"\n",
    "    ],\n",
    "    \"langfuse.environment\": \"development\"\n",
    "}\n",
    "\n",
    "# Test Definition and Execution using LiteLLM endpoints\n",
    "results1 = tester.run_test(\n",
    "    models=[\n",
    "        \"bedrock/openai.gpt-oss-120b-1:0\",\n",
    "        \"bedrock/us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "    ],  # LiteLLM endpoints\n",
    "    system_prompts=[\"version2\"],  # System prompts list to test\n",
    "    queries=test_queries[0],  # Queries to test\n",
    "    prompts_dict=prompts,  # Dictionary of prompts\n",
    "    tool=tool_list,  # Tools to test\n",
    "    save_to_csv=True, # Default True\n",
    "    trace_attributes=trace_attributes\n",
    ")\n",
    "\n",
    "tester.display_results(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting LiteLLM Test Suite\n",
      "üìä Total combinations to test: 2\n",
      "ü§ñ Models: ['bedrock/us.anthropic.claude-3-5-sonnet-20241022-v2:0']\n",
      "üìù Prompts: ['version1', 'version2']\n",
      "‚ùì Queries: 1 query(ies)\n",
      "================================================================================\n",
      "\n",
      "[1/2] Testing: bedrock/us.anthropic.claude-3-5-sonnet-20241022-v2:0 | version1\n",
      "Query: What is the current bitcoin price?\n",
      "------------------------------------------------------------\n",
      "üîß Using AWS region: us-east-1\n",
      "I apologize, but I notice that among the available tools, I don't have direct access to real-time cryptocurrency price data. While I'm designed to coordinate with a CryptoExpertAgent for such queries, I don't currently have a tool to fetch current Bitcoin prices.\n",
      "\n",
      "To provide accurate and real-time cryptocurrency information, I would need access to a cryptocurrency price data feed or API. Without this, I cannot provide you with the current Bitcoin price.\n",
      "\n",
      "If you need this information, I recommend:\n",
      "1. Checking reputable cryptocurrency exchanges directly\n",
      "2. Using cryptocurrency price tracking websites\n",
      "3. Consulting your financial advisor or trading platform\n",
      "\n",
      "Would you like to ask about something else that I can help you with using the available tools?‚úÖ SUCCESS | Time: 5.67s\n",
      "\n",
      "[2/2] Testing: bedrock/us.anthropic.claude-3-5-sonnet-20241022-v2:0 | version2\n",
      "Query: What is the current bitcoin price?\n",
      "------------------------------------------------------------\n",
      "üîß Using AWS region: us-east-1\n",
      "I apologize, but I don't have a direct tool available to fetch real-time Bitcoin prices. While I'm designed to provide financial information and insights, I currently don't have access to live cryptocurrency market data. \n",
      "\n",
      "To get accurate Bitcoin price information, I would recommend:\n",
      "\n",
      "1. Checking major cryptocurrency exchanges like Coinbase, Binance, or Kraken\n",
      "2. Using financial websites like CoinGecko or CoinMarketCap\n",
      "3. Consulting your preferred financial data provider\n",
      "\n",
      "Remember that cryptocurrency prices can be highly volatile and may vary slightly across different exchanges. Always verify prices from reliable sources when making financial decisions.‚úÖ SUCCESS | Time: 7.01s\n",
      "\n",
      "üéâ Test Suite Completed! 2 results generated.\n",
      "üìÅ Results automatically saved to test_results/test_results_20251104_225925.csv\n",
      "\n",
      "üìà RESULTS SUMMARY\n",
      "==================================================\n",
      "Total Tests: 2\n",
      "‚úÖ Successful: 2 (100.0%)\n",
      "‚ùå Failed: 0 (0.0%)\n",
      "‚è±Ô∏è  Response Times - Avg: 6.34s | Min: 5.67s | Max: 7.01s\n",
      "\n",
      "ü§ñ MODEL PERFORMANCE\n",
      "==================================================\n",
      "bedrock/us.anthropic.claude-3-5-sonnet-20241022-v2:0 | Success: 100.0% | Avg Time:   6.34s | Tests: 2\n",
      "\n",
      "üìù PROMPT PERFORMANCE\n",
      "==================================================\n",
      "version1             | Success: 100.0% | Avg Time:   5.67s | Tests: 1\n",
      "version2             | Success: 100.0% | Avg Time:   7.01s | Tests: 1\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Single LiteLLM model, multiple prompts, single query\n",
    "\n",
    "#Test name\n",
    "test_name = \"Restaurant helper LiteLLM\"\n",
    "\n",
    "#Langfuse trace attributes\n",
    "trace_attributes = {\n",
    "    # Main trace name \n",
    "    \"operation.name\": test_name, \n",
    "    \"langfuse.trace.name\": test_name,\n",
    "    # Core identifiers\n",
    "    \"session.id\": session_id,\n",
    "    \"user.id\": \"palacan@amazon.com\",\n",
    "    # Langfuse metadata\n",
    "    \"langfuse.tags\": [\n",
    "        f\"Agent-{test_name}\"\n",
    "    ],\n",
    "    \"langfuse.environment\": \"development\"\n",
    "}\n",
    "\n",
    "results2 = tester.run_test(\n",
    "    models=[\"bedrock/us.anthropic.claude-3-5-sonnet-20241022-v2:0\"],  # Single LiteLLM endpoint\n",
    "    system_prompts=[\"version1\", \"version2\"],  # Multiple prompts\n",
    "    queries=test_queries[0],  # Single query\n",
    "    prompts_dict=prompts,\n",
    "    tool=tool_list,\n",
    "    trace_attributes=trace_attributes\n",
    ")\n",
    "\n",
    "tester.display_results(results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] üß™ Test Case Evaluation with LLM-as-Judge using LiteLLM\n",
    "\n",
    "This section demonstrates how to run structured test case evaluation using the `run_evaluation()` method with LiteLLM endpoints. This method:\n",
    "\n",
    "- Loads test cases from `config_evaluation.yaml`\n",
    "- Runs multi-turn conversations for each test case\n",
    "- Uses an LLM-as-judge to evaluate responses against expected results\n",
    "- Provides detailed scoring and analysis\n",
    "- Optionally integrates with Langfuse for tracing\n",
    "\n",
    "## Agent Evaluation (csv output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Starting LiteLLM Test Case Evaluation\n",
      "üìä Total combinations: 2\n",
      "ü§ñ Models: ['bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0']\n",
      "üìù Prompts: ['version2']\n",
      "üìã Test Cases: 2 test case(s)\n",
      "================================================================================\n",
      "\n",
      "[1/2] Evaluating: bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0 | version2 | comparacion_crypto_tradicional\n",
      "------------------------------------------------------------\n",
      "üîß Using AWS region: us-east-1\n",
      "üìù Test Case: comparacion_crypto_tradicional\n",
      "\n",
      "  Turn 1: ¬øPuedes proporcionarme una comparaci√≥n entre los precios de ...\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "    ‚ùå Error in question 1: litellm.BadRequestError: BedrockException - b'{\"message\":\"Invocation of model ID anthropic.claude-3-5-sonnet-20241022-v2:0 with on-demand throughput isn\\xe2\\x80\\x99t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\"}'\n",
      "‚ùå FAILED | Score: 0.00\n",
      "\n",
      "[2/2] Evaluating: bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0 | version2 | escenario_analisis_accion_individual\n",
      "------------------------------------------------------------\n",
      "üîß Using AWS region: us-east-1\n",
      "üìù Test Case: escenario_analisis_accion_individual\n",
      "\n",
      "  Turn 1: Necesito informaci√≥n sobre el rendimiento actual de Apple (A...\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "    ‚ùå Error in question 1: litellm.BadRequestError: BedrockException - b'{\"message\":\"Invocation of model ID anthropic.claude-3-5-sonnet-20241022-v2:0 with on-demand throughput isn\\xe2\\x80\\x99t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\"}'\n",
      "\n",
      "  Turn 2: ¬øC√≥mo se compara el rendimiento de Apple con el sector tecno...\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "    ‚ùå Error in question 2: litellm.BadRequestError: BedrockException - b'{\"message\":\"Invocation of model ID anthropic.claude-3-5-sonnet-20241022-v2:0 with on-demand throughput isn\\xe2\\x80\\x99t supported. Retry your request with the ID or ARN of an inference profile that contains this model.\"}'\n",
      "‚ùå FAILED | Score: 0.00\n",
      "\n",
      "üéâ Evaluation Completed! 2 results generated.\n",
      "\n",
      "üìä EVALUATION SUMMARY\n",
      "==================================================\n",
      "Total Test Cases: 2\n",
      "‚úÖ Passed: 0 (0.0%)\n",
      "‚ùå Failed: 2 (100.0%)\n",
      "üìà Average Score: 0.00\n",
      "\n",
      "ü§ñ MODEL PERFORMANCE\n",
      "==================================================\n",
      "bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0 | Score:  0.00 | Passed: 0/2\n",
      "\n",
      "üìù PROMPT PERFORMANCE\n",
      "==================================================\n",
      "version2             | Score:  0.00 | Passed: 0/2\n",
      "üìÅ Evaluation results exported to evaluation_results/evaluation_results_20251104_230001.csv\n",
      "\n",
      "‚úÖ Evaluation completed with 2 test case results\n"
     ]
    }
   ],
   "source": [
    "# Load system prompts for evaluation\n",
    "with open('config_experiments.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "prompts = config['system_prompts']\n",
    "os.environ[\"KNOWLEDGE_BASE_ID\"] = kb_id[\"Parameter\"][\"Value\"]\n",
    "tool_list = [retrieve, current_time, tool_get_booking_details, tool_create_booking, tool_delete_booking]\n",
    "\n",
    "# Run evaluation with test cases using LiteLLM\n",
    "evaluation_results = tester.run_evaluation(\n",
    "    models=[\"bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0\"],  # LiteLLM endpoint\n",
    "    system_prompts=[\"version2\"],  # Single prompt version\n",
    "    prompts_dict=prompts,\n",
    "    tool=tool_list,\n",
    "    test_cases_path=\"config_evaluation.yml\",  # Test cases file\n",
    "    save_to_csv=True  # Save results to CSV\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation completed with {len(evaluation_results)} test case results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Model Evaluation Comparison with LiteLLM\n",
    "\n",
    "Compare multiple LiteLLM models and prompts across all test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation across multiple LiteLLM configurations\n",
    "# WARNING!!: This will take longer as it tests all combinations\n",
    "\n",
    "comprehensive_evaluation = tester.run_evaluation(\n",
    "    models=[\n",
    "        \"bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "        \"bedrock/amazon.nova-pro-v1:0\"\n",
    "    ],  # Multiple LiteLLM endpoints\n",
    "    system_prompts=[\"version2\"],   # Multiple prompts\n",
    "    prompts_dict=prompts,\n",
    "    tool=tool_list,\n",
    "    test_cases_path=\"config_evaluation.yml\",\n",
    "    save_to_csv=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Comprehensive evaluation completed with {len(comprehensive_evaluation)} results\")\n",
    "print(\"\\nüìä Detailed analysis shows model and prompt performance across all test cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß LiteLLM Configuration Tips\n",
    "\n",
    "### Environment Variables for AWS Bedrock\n",
    "Make sure you have AWS credentials configured:\n",
    "```bash\n",
    "export AWS_ACCESS_KEY_ID=your_access_key\n",
    "export AWS_SECRET_ACCESS_KEY=your_secret_key\n",
    "export AWS_REGION=us-east-1\n",
    "```\n",
    "\n",
    "### Other Provider Examples\n",
    "```python\n",
    "# OpenAI\n",
    "models = [\"gpt-4\", \"gpt-3.5-turbo\"]\n",
    "\n",
    "# Anthropic Direct\n",
    "models = [\"claude-3-sonnet-20240229\"]\n",
    "\n",
    "# Azure OpenAI\n",
    "models = [\"azure/gpt-4\"]\n",
    "```\n",
    "\n",
    "### Benefits of LiteLLM Integration\n",
    "- **Unified Interface**: Same code works with 100+ LLM providers\n",
    "- **Easy Switching**: Change models without code changes\n",
    "- **Cost Optimization**: Compare costs across providers\n",
    "- **Fallback Support**: Automatic failover between models\n",
    "- **Rate Limiting**: Built-in rate limiting and retry logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
