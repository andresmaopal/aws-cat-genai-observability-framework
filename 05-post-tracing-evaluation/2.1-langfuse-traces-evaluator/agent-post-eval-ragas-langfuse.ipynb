{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Agent Evaluation (Ragas and LangFuse)\n",
    "\n",
    "This notebook provides a streamlined interface for evaluating agent performance using RAGAS metrics and LangFuse traces. All evaluation logic has been moved to `utils.py` and metrics are configured in `metrics_config.yaml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install ragas \"strands-agents==0.1.9\" \"strands-agents-tools==0.1.7\" \"langfuse==3.1.1\" pyyaml -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from utils import run_evaluation_pipeline, print_metric_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration of Test Parameters\n",
    "\n",
    "Modify these parameters according to your evaluation needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS - MODIFY AS NEEDED\n",
    "# =============================================================================\n",
    "\n",
    "# LangFuse Configuration\n",
    "LANGFUSE_SECRET_KEY = \"sk-lf-xxxxxxxx\"\n",
    "LANGFUSE_PUBLIC_KEY = \"pk-lf-xxxxxxxx\"\n",
    "LANGFUSE_HOST = \"https://us.cloud.langfuse.com\"\n",
    "\n",
    "# Evaluation Parameters\n",
    "LOOKBACK_HOURS = 24          # Hours to look back for traces\n",
    "BATCH_SIZE = 20              # Number of traces to process\n",
    "LANGFUSE_TAGS = [\"Observability-Tutorial\"]  # Filter traces by tags (None for all)\n",
    "SAVE_CSV = True              # Save results to CSV files\n",
    "\n",
    "# Target LLM-as-Judge Model (from model_list.json)\n",
    "TARGET_MODEL = \"claude-3.7-sonnet\"  # Available models: claude-4-sonnet, nova-premier, etc.\n",
    "\n",
    "# File Paths\n",
    "METRICS_CONFIG_PATH = \"metrics_config.yaml\"\n",
    "MODEL_LIST_PATH = \"model_list.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment configured for LangFuse host: http://langfu-loadb-ukoqudmq8a8v-2110705221.us-east-1.elb.amazonaws.com\n",
      "Target evaluation model: claude-3.7-sonnet\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "os.environ[\"AWS_REGION_NAME\"] = \"us-east-1\"\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = LANGFUSE_SECRET_KEY\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = LANGFUSE_PUBLIC_KEY\n",
    "os.environ[\"LANGFUSE_HOST\"] = LANGFUSE_HOST\n",
    "\n",
    "# Setup OpenTelemetry endpoint\n",
    "otel_endpoint = LANGFUSE_HOST + \"/api/public/otel/v1/traces\"\n",
    "auth_token = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = otel_endpoint\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {auth_token}\"\n",
    "\n",
    "print(f\"Environment configured for LangFuse host: {LANGFUSE_HOST}\")\n",
    "print(f\"Target evaluation model: {TARGET_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation Pipeline\n",
    "\n",
    "Execute the complete evaluation pipeline with the configured parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RAGAS evaluation pipeline...\n",
      "Configuration: 24h lookback, 20 traces, model: claude-3.7-sonnet\n",
      "Fetching traces from 2025-10-28 04:10:22.933937 to 2025-10-29 04:10:22.933937\n",
      "No traces found with time filter, trying without time constraints...\n",
      "Fetched 20 traces\n",
      "Evaluating 15 multi_turn samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6733c3e9ded34e008b93a0297db8cf3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added score Task/Objective Achieved=1.0 to trace 88d219576171ad507d88c34c873c64a3\n",
      "Added score Tone of the Agent Metric=1.0 to trace 88d219576171ad507d88c34c873c64a3\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 88d219576171ad507d88c34c873c64a3\n",
      "Added score Policy Compliance=1.0 to trace 88d219576171ad507d88c34c873c64a3\n",
      "Added score Answer Correctness=4.0 to trace 88d219576171ad507d88c34c873c64a3\n",
      "Added score Task/Objective Achieved=0.0 to trace c05cbb09247386e50cb4c1a633aa8c4c\n",
      "Added score Tone of the Agent Metric=1.0 to trace c05cbb09247386e50cb4c1a633aa8c4c\n",
      "Added score Tool Usage Effectiveness=0.0 to trace c05cbb09247386e50cb4c1a633aa8c4c\n",
      "Added score Policy Compliance=1.0 to trace c05cbb09247386e50cb4c1a633aa8c4c\n",
      "Added score Answer Correctness=5.0 to trace c05cbb09247386e50cb4c1a633aa8c4c\n",
      "Added score Task/Objective Achieved=0.0 to trace d586b4dca7121b0a830f1283b8fe97ca\n",
      "Added score Tone of the Agent Metric=1.0 to trace d586b4dca7121b0a830f1283b8fe97ca\n",
      "Added score Tool Usage Effectiveness=0.0 to trace d586b4dca7121b0a830f1283b8fe97ca\n",
      "Added score Policy Compliance=1.0 to trace d586b4dca7121b0a830f1283b8fe97ca\n",
      "Added score Answer Correctness=5.0 to trace d586b4dca7121b0a830f1283b8fe97ca\n",
      "Added score Task/Objective Achieved=1.0 to trace 1f35c3bfc83e849d66ce768af4adeee6\n",
      "Added score Tone of the Agent Metric=1.0 to trace 1f35c3bfc83e849d66ce768af4adeee6\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 1f35c3bfc83e849d66ce768af4adeee6\n",
      "Added score Policy Compliance=1.0 to trace 1f35c3bfc83e849d66ce768af4adeee6\n",
      "Added score Answer Correctness=5.0 to trace 1f35c3bfc83e849d66ce768af4adeee6\n",
      "Added score Task/Objective Achieved=0.0 to trace b1bb965b04d4da78ce549928f0277a5c\n",
      "Added score Tone of the Agent Metric=1.0 to trace b1bb965b04d4da78ce549928f0277a5c\n",
      "Added score Tool Usage Effectiveness=1.0 to trace b1bb965b04d4da78ce549928f0277a5c\n",
      "Added score Policy Compliance=1.0 to trace b1bb965b04d4da78ce549928f0277a5c\n",
      "Added score Answer Correctness=5.0 to trace b1bb965b04d4da78ce549928f0277a5c\n",
      "Added score Task/Objective Achieved=1.0 to trace 151dfd154dd430203a4e623afd43d9a9\n",
      "Added score Tone of the Agent Metric=1.0 to trace 151dfd154dd430203a4e623afd43d9a9\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 151dfd154dd430203a4e623afd43d9a9\n",
      "Added score Policy Compliance=1.0 to trace 151dfd154dd430203a4e623afd43d9a9\n",
      "Added score Answer Correctness=5.0 to trace 151dfd154dd430203a4e623afd43d9a9\n",
      "Added score Task/Objective Achieved=0.0 to trace 92a4097fc0084c8da3353832170c0a2c\n",
      "Added score Tone of the Agent Metric=1.0 to trace 92a4097fc0084c8da3353832170c0a2c\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 92a4097fc0084c8da3353832170c0a2c\n",
      "Added score Policy Compliance=1.0 to trace 92a4097fc0084c8da3353832170c0a2c\n",
      "Added score Answer Correctness=5.0 to trace 92a4097fc0084c8da3353832170c0a2c\n",
      "Added score Task/Objective Achieved=1.0 to trace 9eb047ec11a7db874da38b18ecd955cc\n",
      "Added score Tone of the Agent Metric=1.0 to trace 9eb047ec11a7db874da38b18ecd955cc\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 9eb047ec11a7db874da38b18ecd955cc\n",
      "Added score Policy Compliance=1.0 to trace 9eb047ec11a7db874da38b18ecd955cc\n",
      "Added score Answer Correctness=5.0 to trace 9eb047ec11a7db874da38b18ecd955cc\n",
      "Added score Task/Objective Achieved=0.0 to trace fd528ed4e0f15e627838b8fa1124ee13\n",
      "Added score Tone of the Agent Metric=0.0 to trace fd528ed4e0f15e627838b8fa1124ee13\n",
      "Added score Tool Usage Effectiveness=0.0 to trace fd528ed4e0f15e627838b8fa1124ee13\n",
      "Added score Policy Compliance=1.0 to trace fd528ed4e0f15e627838b8fa1124ee13\n",
      "Added score Answer Correctness=3.0 to trace fd528ed4e0f15e627838b8fa1124ee13\n",
      "Added score Task/Objective Achieved=1.0 to trace 7d063e3a74bff04250887b05f2ec6c3e\n",
      "Added score Tone of the Agent Metric=1.0 to trace 7d063e3a74bff04250887b05f2ec6c3e\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 7d063e3a74bff04250887b05f2ec6c3e\n",
      "Added score Policy Compliance=1.0 to trace 7d063e3a74bff04250887b05f2ec6c3e\n",
      "Added score Answer Correctness=5.0 to trace 7d063e3a74bff04250887b05f2ec6c3e\n",
      "Added score Task/Objective Achieved=1.0 to trace 1f358c72dfe5e93672a6d108dda23401\n",
      "Added score Tone of the Agent Metric=1.0 to trace 1f358c72dfe5e93672a6d108dda23401\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 1f358c72dfe5e93672a6d108dda23401\n",
      "Added score Policy Compliance=1.0 to trace 1f358c72dfe5e93672a6d108dda23401\n",
      "Added score Answer Correctness=5.0 to trace 1f358c72dfe5e93672a6d108dda23401\n",
      "Added score Task/Objective Achieved=0.0 to trace 993376acd0f0996db74117a0e91e54f9\n",
      "Added score Tone of the Agent Metric=0.0 to trace 993376acd0f0996db74117a0e91e54f9\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 993376acd0f0996db74117a0e91e54f9\n",
      "Added score Policy Compliance=1.0 to trace 993376acd0f0996db74117a0e91e54f9\n",
      "Added score Answer Correctness=2.0 to trace 993376acd0f0996db74117a0e91e54f9\n",
      "Added score Task/Objective Achieved=1.0 to trace ab43b807962c1f6fffbd602c4af7d8cf\n",
      "Added score Tone of the Agent Metric=1.0 to trace ab43b807962c1f6fffbd602c4af7d8cf\n",
      "Added score Tool Usage Effectiveness=1.0 to trace ab43b807962c1f6fffbd602c4af7d8cf\n",
      "Added score Policy Compliance=1.0 to trace ab43b807962c1f6fffbd602c4af7d8cf\n",
      "Added score Answer Correctness=5.0 to trace ab43b807962c1f6fffbd602c4af7d8cf\n",
      "Added score Task/Objective Achieved=1.0 to trace 34fae872b64b7fd082176f3d2f815aeb\n",
      "Added score Tone of the Agent Metric=1.0 to trace 34fae872b64b7fd082176f3d2f815aeb\n",
      "Added score Tool Usage Effectiveness=1.0 to trace 34fae872b64b7fd082176f3d2f815aeb\n",
      "Added score Policy Compliance=1.0 to trace 34fae872b64b7fd082176f3d2f815aeb\n",
      "Added score Answer Correctness=5.0 to trace 34fae872b64b7fd082176f3d2f815aeb\n",
      "Added score Task/Objective Achieved=0.0 to trace a91a018fa8d8dbeadb9c8efc70ce16d8\n",
      "Added score Tone of the Agent Metric=0.0 to trace a91a018fa8d8dbeadb9c8efc70ce16d8\n",
      "Added score Tool Usage Effectiveness=0.0 to trace a91a018fa8d8dbeadb9c8efc70ce16d8\n",
      "Added score Policy Compliance=1.0 to trace a91a018fa8d8dbeadb9c8efc70ce16d8\n",
      "Added score Answer Correctness=1.0 to trace a91a018fa8d8dbeadb9c8efc70ce16d8\n",
      "Results saved to evaluation_results/conversation_evaluation_20251029_041116.csv\n",
      "Evaluating 5 single_turn samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb2ab48321442feb29d941a57422b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error adding score: float() argument must be a string or a real number, not 'list'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Error adding score: could not convert string to float: '<answer> Restaurant Helper: Your reservation for tonight at Rice & Spice for 5 persons at 8pm under the name Andres has been successfully created. Your booking ID is 5c73b5a3. </answer>\\n'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Added score Task/Objective Achieved=1.0 to trace 21446e18d418b07a7c70b8ffca4c9145\n",
      "Added score Tone of the Agent Metric=1.0 to trace 21446e18d418b07a7c70b8ffca4c9145\n",
      "Added score Tool Usage Effectiveness=0.0 to trace 21446e18d418b07a7c70b8ffca4c9145\n",
      "Added score Policy Compliance=1.0 to trace 21446e18d418b07a7c70b8ffca4c9145\n",
      "Added score Answer Correctness=5.0 to trace 21446e18d418b07a7c70b8ffca4c9145\n",
      "Error adding score: float() argument must be a string or a real number, not 'list'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Error adding score: could not convert string to float: '<answer> Restaurant Helper: The reservation for Andres at Rice & Spice for 5 persons tonight at 8pm has been successfully canceled. If you need further assistance, please do not hesitate to contact us. </answer>\\n'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Added score Task/Objective Achieved=1.0 to trace 89bb256279610cb2e64451a29eb2bf37\n",
      "Added score Tone of the Agent Metric=1.0 to trace 89bb256279610cb2e64451a29eb2bf37\n",
      "Added score Tool Usage Effectiveness=0.0 to trace 89bb256279610cb2e64451a29eb2bf37\n",
      "Added score Policy Compliance=1.0 to trace 89bb256279610cb2e64451a29eb2bf37\n",
      "Added score Answer Correctness=5.0 to trace 89bb256279610cb2e64451a29eb2bf37\n",
      "Error adding score: float() argument must be a string or a real number, not 'list'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Error adding score: could not convert string to float: '<thinking> The booking has been successfully created with the booking ID e2563691. I will now inform the user of the successful reservation. </thinking>\\n<answer> Restaurant Helper: Your reservation for tonight at 8pm for 5 persons at Rice & Spice under the name Andres has been successfully created. Your booking ID is e2563691. Enjoy your dining experience! </answer>\\n'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Added score Task/Objective Achieved=1.0 to trace 86680adf0a6442445dfbded04939f8e5\n",
      "Added score Tone of the Agent Metric=1.0 to trace 86680adf0a6442445dfbded04939f8e5\n",
      "Added score Tool Usage Effectiveness=0.0 to trace 86680adf0a6442445dfbded04939f8e5\n",
      "Added score Policy Compliance=1.0 to trace 86680adf0a6442445dfbded04939f8e5\n",
      "Added score Answer Correctness=3.0 to trace 86680adf0a6442445dfbded04939f8e5\n",
      "Error adding score: float() argument must be a string or a real number, not 'list'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Error adding score: could not convert string to float: '<thinking> The reservation has been successfully created with booking id 69e64768. I will inform the user of the successful reservation. </thinking> <answer> Restaurant Helper: Your reservation for tonight at 8pm for 5 persons in the name of Andres at Rice & Spice has been successfully created. Your booking ID is 69e64768. If you have any further requests or need assistance, please let me know. </answer>\\n'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Added score Task/Objective Achieved=1.0 to trace 14aca83196ad859ced92aa626561e617\n",
      "Added score Tone of the Agent Metric=1.0 to trace 14aca83196ad859ced92aa626561e617\n",
      "Added score Tool Usage Effectiveness=0.0 to trace 14aca83196ad859ced92aa626561e617\n",
      "Added score Policy Compliance=1.0 to trace 14aca83196ad859ced92aa626561e617\n",
      "Added score Answer Correctness=5.0 to trace 14aca83196ad859ced92aa626561e617\n",
      "Error adding score: float() argument must be a string or a real number, not 'list'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Error adding score: could not convert string to float: '<thinking> The booking has been successfully created with the booking id 35e802f4. I should inform the user about the successful reservation. </thinking> <answer> Restaurant Helper: Your reservation for tonight at 8pm for 5 persons at Rice & Spice in the name of Andres has been successfully created. Your booking ID is 35e802f4. If you need any further assistance, please do not hesitate to ask. </answer>\\n'\n",
      "Both scoring methods failed: 'Langfuse' object has no attribute 'score'\n",
      "Added score Task/Objective Achieved=1.0 to trace cbd571063cf170f01f9a5bd5dc233e14\n",
      "Added score Tone of the Agent Metric=1.0 to trace cbd571063cf170f01f9a5bd5dc233e14\n",
      "Added score Tool Usage Effectiveness=0.0 to trace cbd571063cf170f01f9a5bd5dc233e14\n",
      "Added score Policy Compliance=1.0 to trace cbd571063cf170f01f9a5bd5dc233e14\n",
      "Added score Answer Correctness=5.0 to trace cbd571063cf170f01f9a5bd5dc233e14\n",
      "Results saved to evaluation_results/single_turn_evaluation_20251029_041137.csv\n",
      "\n",
      "Evaluation pipeline completed!\n"
     ]
    }
   ],
   "source": [
    "# Prepare LangFuse configuration\n",
    "langfuse_config = {\n",
    "    \"secret_key\": LANGFUSE_SECRET_KEY,\n",
    "    \"public_key\": LANGFUSE_PUBLIC_KEY,\n",
    "    \"host\": LANGFUSE_HOST\n",
    "}\n",
    "\n",
    "# Run the evaluation pipeline\n",
    "print(\"Starting RAGAS evaluation pipeline...\")\n",
    "print(f\"Configuration: {LOOKBACK_HOURS}h lookback, {BATCH_SIZE} traces, model: {TARGET_MODEL}\")\n",
    "\n",
    "results = run_evaluation_pipeline(\n",
    "    langfuse_config=langfuse_config,\n",
    "    model_name=TARGET_MODEL,\n",
    "    lookback_hours=LOOKBACK_HOURS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    tags=LANGFUSE_TAGS,\n",
    "    save_csv=SAVE_CSV,\n",
    "    metrics_config_path=METRICS_CONFIG_PATH,\n",
    "    model_list_path=MODEL_LIST_PATH\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation pipeline completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  MULTI-TURN CONVERSATION EVALUATION\n",
      "============================================================\n",
      "üìä Samples Evaluated: 15\n",
      "\n",
      "üìà METRIC SCORES SUMMARY\n",
      "----------------------------------------\n",
      "\n",
      "Task/Objective Achieved:\n",
      "  Mean: 0.533 | Min: 0.000 | Max: 1.000 | üü† NEEDS IMPROVEMENT\n",
      "\n",
      "Tone of the Agent Metric:\n",
      "  Mean: 0.800 | Min: 0.000 | Max: 1.000 | üü¢ EXCELLENT\n",
      "\n",
      "Tool Usage Effectiveness:\n",
      "  Mean: 0.733 | Min: 0.000 | Max: 1.000 | üü° GOOD\n",
      "\n",
      "Policy Compliance:\n",
      "  Mean: 1.000 | Min: 1.000 | Max: 1.000 | üü¢ EXCELLENT\n",
      "\n",
      "Answer Correctness:\n",
      "  Mean: 4.333 | Min: 1.000 | Max: 5.000 | üü¢ EXCELLENT\n",
      "\n",
      "============================================================\n",
      "  SINGLE-TURN EVALUATION\n",
      "============================================================\n",
      "üìä Samples Evaluated: 5\n",
      "\n",
      "üìà METRIC SCORES SUMMARY\n",
      "----------------------------------------\n",
      "\n",
      "Task/Objective Achieved:\n",
      "  Mean: 1.000 | Min: 1.000 | Max: 1.000 | üü¢ EXCELLENT\n",
      "\n",
      "Tone of the Agent Metric:\n",
      "  Mean: 1.000 | Min: 1.000 | Max: 1.000 | üü¢ EXCELLENT\n",
      "\n",
      "Tool Usage Effectiveness:\n",
      "  Mean: 0.000 | Min: 0.000 | Max: 0.000 | üî¥ POOR\n",
      "\n",
      "Policy Compliance:\n",
      "  Mean: 1.000 | Min: 1.000 | Max: 1.000 | üü¢ EXCELLENT\n",
      "\n",
      "Answer Correctness:\n",
      "  Mean: 4.600 | Min: 3.000 | Max: 5.000 | üü¢ EXCELLENT\n"
     ]
    }
   ],
   "source": [
    "# Display results summary with configurable performance ranges\n",
    "if results:\n",
    "    \n",
    "    has_results = False\n",
    "    \n",
    "    # Performance range configuration - adjust as needed\n",
    "    # Examples: [0, 1] for 0-1 scale, [1, 5] for 1-5 scale\n",
    "    PERFORMANCE_RANGE = [0, 1]  # Change this to [1, 5] for 1-5 scale evaluation\n",
    "    \n",
    "    if \"conversation_results\" in results and results[\"conversation_results\"] is not None:\n",
    "        if not results[\"conversation_results\"].empty:\n",
    "            print_metric_summary(\n",
    "                results[\"conversation_results\"], \n",
    "                \"MULTI-TURN CONVERSATION EVALUATION\",\n",
    "                performance_range=PERFORMANCE_RANGE\n",
    "            )\n",
    "            has_results = True\n",
    "    \n",
    "    if \"single_turn_results\" in results and results[\"single_turn_results\"] is not None:\n",
    "        if not results[\"single_turn_results\"].empty:\n",
    "            print_metric_summary(\n",
    "                results[\"single_turn_results\"], \n",
    "                \"SINGLE-TURN EVALUATION\",\n",
    "                performance_range=PERFORMANCE_RANGE\n",
    "            )\n",
    "            has_results = True\n",
    "    \n",
    "    if not has_results:\n",
    "        print(\"\\n‚ö†Ô∏è  No evaluation results available - check trace availability and configuration\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No results returned from evaluation pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
